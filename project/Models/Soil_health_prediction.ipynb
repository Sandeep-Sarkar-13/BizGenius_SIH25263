{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q xgboost==1.7.6 lightgbm==3.3.5 shap==0.41.0 joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvyTE2C5GKWc",
        "outputId": "c50064a9-a9dd-4466-8811-4956f2e32223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/380.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m286.7/380.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for shap (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 shap==0.41.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "qwVcYySJHy_Y",
        "outputId": "6e3d33ca-2b3e-49e9-9660-276db83f3d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shap==0.41.0 in /usr/local/lib/python3.12/dist-packages (0.41.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap==0.41.0) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap==0.41.0) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap==0.41.0) (2.2.2)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.12/dist-packages (from shap==0.41.0) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap==0.41.0) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.12/dist-packages (from shap==0.41.0) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from shap==0.41.0) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap==0.41.0) (3.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->shap==0.41.0) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shap==0.41.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap==0.41.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap==0.41.0) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap==0.41.0) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap==0.41.0) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shap==0.41.0) (1.17.0)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "94e8cda14ac940d4a32117a1387416bd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SOIL_HEALTH**"
      ],
      "metadata": {
        "id": "UEWB2QwiOThE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smqqYAr9F7c4",
        "outputId": "c112e723-4d7c-4ff0-c011-1f595d59e8f3"
      },
      "source": [
        "# Modified combined-training script with anti-overfitting measures\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, brier_score_loss\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from joblib import dump, load\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SYNTHETIC_PATH = '/content/drive/MyDrive/FarmEasy/soil/soil_synthetic_rice_12000.csv'\n",
        "SENSOR_PATH    = '/content/drive/MyDrive/FarmEasy/soil/sensor_data_with_fertility.csv'\n",
        "OUTPUT_MODEL_DIR = '/content/drive/MyDrive/FarmEasy/soil/soil_model_combined_output_nooverfit'\n",
        "os.makedirs(OUTPUT_MODEL_DIR, exist_ok=True)\n",
        "RNG_SEED = 42\n",
        "\n",
        "FEATURE_COLS = ['Moisture_%','Temperature_C','EC_uS_cm','pH','N_mg_per_kg','P_mg_per_kg','K_mg_per_kg']\n",
        "\n",
        "sensor_rename_map = {\n",
        "    \"Moist (%)\": \"Moisture_%\",\n",
        "    \"Temp (C)\": \"Temperature_C\",\n",
        "    \"EC (uS/cm)\": \"EC_uS_cm\",\n",
        "    \"N (mg/kg)\": \"N_mg_per_kg\",\n",
        "    \"P (mg/kg)\": \"P_mg_per_kg\",\n",
        "    \"K (mg/kg)\": \"K_mg_per_kg\",\n",
        "    \"Timestamp\": \"Timestamp\"\n",
        "}\n",
        "\n",
        "np.random.seed(RNG_SEED)\n",
        "\n",
        "# ---------- 1) Load ----------\n",
        "print(\"Loading datasets...\")\n",
        "df_csv = pd.read_csv(SYNTHETIC_PATH)\n",
        "df_sensor = pd.read_csv(SENSOR_PATH)\n",
        "df_sensor = df_sensor.rename(columns=sensor_rename_map)\n",
        "print(\"Synthetic rows:\", len(df_csv), \"Sensor rows:\", len(df_sensor))\n",
        "\n",
        "# ---------- 2) Ensure feature columns exist ----------\n",
        "for col in FEATURE_COLS:\n",
        "    if col not in df_csv.columns:\n",
        "        raise ValueError(f\"Synthetic CSV missing required column {col}\")\n",
        "    if col not in df_sensor.columns:\n",
        "        df_sensor[col] = np.nan  # we'll impute later\n",
        "\n",
        "# ---------- 3) Targets ----------\n",
        "def to_target_bin(series):\n",
        "    if series.dtype.kind in 'iufc':\n",
        "        return series.astype(int).replace({0:0,1:1})\n",
        "    return series.map(lambda x: 1 if str(x).strip().lower() in ['fertile','1','true','yes','y'] else 0)\n",
        "\n",
        "# synthetic expected to have 'target' = 'fertile'/'non_fertile'\n",
        "if 'target' in df_csv.columns:\n",
        "    df_csv['target_bin'] = to_target_bin(df_csv['target'])\n",
        "else:\n",
        "    raise ValueError(\"Synthetic CSV must have 'target' column\")\n",
        "\n",
        "# sensor: use provided target if exists, else create pseudo-labels (warn)\n",
        "pseudo_label_used = False\n",
        "if 'target' in df_sensor.columns:\n",
        "    df_sensor['target_bin'] = to_target_bin(df_sensor['target'])\n",
        "    print(\"Sensor contains 'target' column; using it.\")\n",
        "else:\n",
        "    pseudo_label_used = True\n",
        "    print(\"Sensor missing 'target' -> creating pseudo-labels using threshold rules (best-effort).\")\n",
        "    df_sensor['target_bin'] = (\n",
        "        ((df_sensor['pH'] >= 5.5) & (df_sensor['pH'] <= 7.5)) &\n",
        "        (df_sensor['EC_uS_cm'] < 1000) &\n",
        "        (df_sensor['Temperature_C'] >= 20) & (df_sensor['Temperature_C'] <= 30) &\n",
        "        (df_sensor['Moisture_%'] >= 30) &\n",
        "        (((df_sensor['N_mg_per_kg'] < 20).fillna(True)).astype(int) + (df_sensor['P_mg_per_kg'] < 12).fillna(True).astype(int) + (df_sensor['K_mg_per_kg'] < 100).fillna(True).astype(int) <= 1)\n",
        "    ).astype(int)\n",
        "\n",
        "df_csv['source'] = 'csv'\n",
        "df_sensor['source'] = 'sensor'\n",
        "\n",
        "# ---------- 4) Concatenate (keep Timestamp if present in sensor) ----------\n",
        "keep_cols = FEATURE_COLS + ['target_bin','source']\n",
        "if 'Timestamp' in df_sensor.columns:\n",
        "    df_sensor_out = df_sensor[FEATURE_COLS + ['target_bin','source','Timestamp']].copy()\n",
        "else:\n",
        "    df_sensor_out = df_sensor[keep_cols].copy()\n",
        "df_csv_sel = df_csv[FEATURE_COLS + ['target_bin','source']].copy()\n",
        "combined = pd.concat([df_csv_sel, df_sensor_out[keep_cols]], ignore_index=True, sort=False).reset_index(drop=True)\n",
        "\n",
        "print(\"Combined size:\", len(combined))\n",
        "print(combined['source'].value_counts())\n",
        "\n",
        "# ---------- 5) Compute sample weights (equal total weight per source) ----------\n",
        "n_csv = (combined['source']=='csv').sum()\n",
        "n_sensor = (combined['source']=='sensor').sum()\n",
        "total = n_csv + n_sensor\n",
        "w_csv = (0.5 * total) / max(n_csv,1)\n",
        "w_sensor = (0.5 * total) / max(n_sensor,1)\n",
        "combined['sample_weight'] = combined['source'].map({'csv': w_csv, 'sensor': w_sensor})\n",
        "print(f\"Per-row weights csv={w_csv:.4f}, sensor={w_sensor:.4f}\")\n",
        "\n",
        "# ---------- 6) Prepare features/labels and simple median imputation ----------\n",
        "X_all = combined[FEATURE_COLS].copy()\n",
        "y_all = combined['target_bin'].copy()\n",
        "sw_all = combined['sample_weight'].values\n",
        "X_all = X_all.fillna(X_all.median())\n",
        "\n",
        "# ---------- 7) Train/test split ----------\n",
        "X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(\n",
        "    X_all, y_all, sw_all, test_size=0.20, stratify=y_all, random_state=RNG_SEED\n",
        ")\n",
        "print(\"Train/Test sizes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# ---------- 8) Scale ----------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "dump(scaler, os.path.join(OUTPUT_MODEL_DIR, 'scaler.joblib'))\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=250,\n",
        "    max_depth=8,\n",
        "    min_samples_leaf=20,\n",
        "    max_features='sqrt',\n",
        "    random_state=RNG_SEED,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    colsample_bytree=0.7,\n",
        "    reg_lambda=2.0,\n",
        "    random_state=RNG_SEED,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    n_jobs=4\n",
        ")\n",
        "\n",
        "\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RNG_SEED)\n",
        "\n",
        "\n",
        "feature_std = X_train_scaled.std(axis=0)\n",
        "\n",
        "AUG_NOISE_FACTOR = 0.03\n",
        "rng = np.random.RandomState(RNG_SEED)\n",
        "\n",
        "def get_oof_predictions_with_augment(clf, X_arr, y_series, X_test_arr, sample_weight_train=None):\n",
        "    oof_train = np.zeros(X_arr.shape[0])\n",
        "    test_preds_folds = np.zeros((X_test_arr.shape[0], n_splits))\n",
        "    for i, (train_idx, val_idx) in enumerate(skf.split(X_arr, y_series)):\n",
        "        X_tr, X_val = X_arr[train_idx].copy(), X_arr[val_idx].copy()\n",
        "        y_tr = y_series.iloc[train_idx]\n",
        "\n",
        "        noise_scale = feature_std * AUG_NOISE_FACTOR\n",
        "        noise = rng.normal(0, noise_scale, size=X_tr.shape)\n",
        "        X_tr_aug = X_tr + noise\n",
        "\n",
        "        if sample_weight_train is not None:\n",
        "            sw_tr = sample_weight_train[train_idx]\n",
        "            clf.fit(X_tr_aug, y_tr, sample_weight=sw_tr)\n",
        "        else:\n",
        "            clf.fit(X_tr_aug, y_tr)\n",
        "\n",
        "        oof_train[val_idx] = clf.predict_proba(X_val)[:,1]\n",
        "        test_preds_folds[:, i] = clf.predict_proba(X_test_arr)[:,1]\n",
        "    test_preds = test_preds_folds.mean(axis=1)\n",
        "    return oof_train.reshape(-1,1), test_preds.reshape(-1,1)\n",
        "\n",
        "X_train_arr = X_train_scaled.copy()\n",
        "X_test_arr = X_test_scaled.copy()\n",
        "sw_train_arr = np.array(sw_train)\n",
        "\n",
        "print(\"Generating OOF predictions for RandomForest (with small augment)...\")\n",
        "rf_oof_train, rf_test_pred = get_oof_predictions_with_augment(rf, X_train_arr, y_train, X_test_arr, sample_weight_train=sw_train_arr)\n",
        "\n",
        "print(\"Generating OOF predictions for XGBoost (with small augment)...\")\n",
        "xgb_oof_train, xgb_test_pred = get_oof_predictions_with_augment(xgb_clf, X_train_arr, y_train, X_test_arr, sample_weight_train=sw_train_arr)\n",
        "\n",
        "X_meta_train = np.hstack([rf_oof_train, xgb_oof_train])\n",
        "X_meta_test  = np.hstack([rf_test_pred, xgb_test_pred])\n",
        "\n",
        "meta = LogisticRegression(C=0.1, max_iter=2000)\n",
        "meta.fit(X_meta_train, y_train, sample_weight=sw_train_arr)\n",
        "\n",
        "calibrator = CalibratedClassifierCV(estimator=meta, method='sigmoid', cv=5)\n",
        "calibrator.fit(X_meta_train, y_train)\n",
        "\n",
        "train_proba = calibrator.predict_proba(X_meta_train)[:,1]\n",
        "train_pred = (train_proba >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\n--- TRAIN (OOF) METRICS ---\")\n",
        "print(classification_report(y_train, train_pred, target_names=['non_fertile','fertile']))\n",
        "print(\"ROC AUC (train):\", round(roc_auc_score(y_train, train_proba),4))\n",
        "print(\"Brier (train):\", round(brier_score_loss(y_train, train_proba),6))\n",
        "print(\"Confusion (train):\\n\", confusion_matrix(y_train, train_pred))\n",
        "\n",
        "rf.fit(X_train_arr, y_train, sample_weight=sw_train_arr)\n",
        "\n",
        "X_xgb_tr, X_xgb_val, y_xgb_tr, y_xgb_val, sw_xgb_tr, sw_xgb_val = train_test_split(\n",
        "    X_train_arr, y_train, sw_train_arr, test_size=0.15, stratify=y_train, random_state=RNG_SEED)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_xgb_tr, label=y_xgb_tr, weight=sw_xgb_tr)\n",
        "dval = xgb.DMatrix(X_xgb_val, label=y_xgb_val, weight=sw_xgb_val)\n",
        "\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 4,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'lambda': 2.0,\n",
        "    'eval_metric': 'logloss',\n",
        "    'seed': RNG_SEED,\n",
        "    'nthread': 4,\n",
        "    'disable_default_get_object': 1\n",
        "}\n",
        "\n",
        "xgb_booster_final = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=1000,\n",
        "    evals=[(dval, 'validation')],\n",
        "    early_stopping_rounds=30,\n",
        "    verbose_eval=False\n",
        ")\n",
        "\n",
        "\n",
        "class XGBBoosterWrapper:\n",
        "    def __init__(self, booster):\n",
        "        self.booster = booster\n",
        "        self.best_iteration = getattr(booster, \"best_iteration\", None)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        d = xgb.DMatrix(X)\n",
        "        p = self.booster.predict(d)\n",
        "        return np.vstack([1 - p, p]).T\n",
        "\n",
        "xgb_wrapper = XGBBoosterWrapper(xgb_booster_final)\n",
        "\n",
        "rf_test_proba  = rf.predict_proba(X_test_arr)[:,1]\n",
        "xgb_test_proba = xgb_wrapper.predict_proba(X_test_arr)[:,1]\n",
        "X_meta_test_final = np.column_stack([rf_test_proba, xgb_test_proba])\n",
        "calib_test_proba = calibrator.predict_proba(X_meta_test_final)[:,1]\n",
        "test_pred = (calib_test_proba >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\n--- TEST METRICS ---\")\n",
        "print(classification_report(y_test, test_pred, target_names=['non_fertile','fertile']))\n",
        "print(\"ROC AUC (test):\", round(roc_auc_score(y_test, calib_test_proba),4))\n",
        "print(\"Brier (test):\", round(brier_score_loss(y_test, calib_test_proba),6))\n",
        "print(\"Confusion (test):\\n\", confusion_matrix(y_test, test_pred))\n",
        "\n",
        "dump(scaler, os.path.join(OUTPUT_MODEL_DIR,'scaler.joblib'))\n",
        "dump(rf, os.path.join(OUTPUT_MODEL_DIR,'rf_model.joblib'))\n",
        "\n",
        "xgb_booster_final.save_model(os.path.join(OUTPUT_MODEL_DIR,'xgb_model.json'))\n",
        "\n",
        "dump(meta, os.path.join(OUTPUT_MODEL_DIR,'meta_lr.joblib'))\n",
        "dump(calibrator, os.path.join(OUTPUT_MODEL_DIR,'calibrator.joblib'))\n",
        "print(\"\\nSaved models to:\", OUTPUT_MODEL_DIR)\n",
        "\n",
        "print(\"\\nTrain label distribution:\", y_train.value_counts().to_dict())\n",
        "print(\"Test label distribution:\", y_test.value_counts().to_dict())\n",
        "if pseudo_label_used:\n",
        "    print(\"\\nNote: sensor data lacked 'target' labels ‚Äî pseudo-labels were used for sensor rows.\")\n",
        "\n",
        "def nutrient_suggestions(row):\n",
        "    issues = []\n",
        "    if row['pH'] < 5.5 or row['pH'] > 7.5:\n",
        "        issues.append(f\"pH_out_of_range ({row['pH']})\")\n",
        "    if row['EC_uS_cm'] >= 1000:\n",
        "        issues.append(f\"High_EC ({row['EC_uS_cm']})\")\n",
        "    if row['Temperature_C'] < 20.0 or row['Temperature_C'] > 30.0:\n",
        "        issues.append(f\"Temperature_off ({row['Temperature_C']} ¬∞C)\")\n",
        "    if row['Moisture_%'] < 30.0:\n",
        "        issues.append(f\"Low_moisture ({row['Moisture_%']}%)\")\n",
        "    if row['N_mg_per_kg'] < 20.0:\n",
        "        issues.append(\"N_def\")\n",
        "    if row['P_mg_per_kg'] < 12.0:\n",
        "        issues.append(\"P_def\")\n",
        "    if row['K_mg_per_kg'] < 100.0:\n",
        "        issues.append(\"K_def\")\n",
        "    return issues\n",
        "\n",
        "loaded_scaler = load(os.path.join(OUTPUT_MODEL_DIR, 'scaler.joblib'))\n",
        "loaded_rf = load(os.path.join(OUTPUT_MODEL_DIR, 'rf_model.joblib'))\n",
        "\n",
        "loaded_xgb_booster = xgb.Booster()\n",
        "loaded_xgb_booster.load_model(os.path.join(OUTPUT_MODEL_DIR,'xgb_model.json'))\n",
        "loaded_calibrator = load(os.path.join(OUTPUT_MODEL_DIR, 'calibrator.joblib'))\n",
        "\n",
        "def predict_sensor_reading(reading_dict):\n",
        "\n",
        "    row_df = pd.DataFrame([reading_dict])\n",
        "\n",
        "    row_df_filled = row_df[FEATURE_COLS].fillna(X_all.median().loc[FEATURE_COLS])\n",
        "\n",
        "    Xr_scaled = loaded_scaler.transform(row_df_filled.values)\n",
        "\n",
        "    p_rf = loaded_rf.predict_proba(Xr_scaled)[:,1]\n",
        "\n",
        "    dX = xgb.DMatrix(Xr_scaled)\n",
        "    p_xgb = loaded_xgb_booster.predict(dX)\n",
        "\n",
        "    p_calib = loaded_calibrator.predict_proba(np.column_stack([p_rf, p_xgb]))[:,1]\n",
        "    label = 'fertile' if p_calib[0] >= 0.5 else 'non_fertile'\n",
        "    issues = nutrient_suggestions(reading_dict)\n",
        "    return {'prob_fertile': float(p_calib[0]), 'label': label, 'issues': issues}\n",
        "\n",
        "example = combined.loc[combined['source']=='sensor'].iloc[0][FEATURE_COLS].to_dict()\n",
        "print(\"\\nExample sensor prediction:\", predict_sensor_reading(example))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "Synthetic rows: 12000 Sensor rows: 263\n",
            "Sensor contains 'target' column; using it.\n",
            "Combined size: 12263\n",
            "source\n",
            "csv       12000\n",
            "sensor      263\n",
            "Name: count, dtype: int64\n",
            "Per-row weights csv=0.5110, sensor=23.3137\n",
            "Train/Test sizes: (9810, 7) (2453, 7)\n",
            "Generating OOF predictions for RandomForest (with small augment)...\n",
            "Generating OOF predictions for XGBoost (with small augment)...\n",
            "\n",
            "--- TRAIN (OOF) METRICS ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " non_fertile       0.99      0.99      0.99      6796\n",
            "     fertile       0.99      0.99      0.99      3014\n",
            "\n",
            "    accuracy                           0.99      9810\n",
            "   macro avg       0.99      0.99      0.99      9810\n",
            "weighted avg       0.99      0.99      0.99      9810\n",
            "\n",
            "ROC AUC (train): 0.9996\n",
            "Brier (train): 0.006122\n",
            "Confusion (train):\n",
            " [[6752   44]\n",
            " [  38 2976]]\n",
            "\n",
            "--- TEST METRICS ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " non_fertile       1.00      1.00      1.00      1699\n",
            "     fertile       1.00      0.99      0.99       754\n",
            "\n",
            "    accuracy                           1.00      2453\n",
            "   macro avg       1.00      1.00      1.00      2453\n",
            "weighted avg       1.00      1.00      1.00      2453\n",
            "\n",
            "ROC AUC (test): 1.0\n",
            "Brier (test): 0.002823\n",
            "Confusion (test):\n",
            " [[1696    3]\n",
            " [   6  748]]\n",
            "\n",
            "Saved models to: /content/drive/MyDrive/FarmEasy/soil/soil_model_combined_output_nooverfit\n",
            "\n",
            "Train label distribution: {0: 6796, 1: 3014}\n",
            "Test label distribution: {0: 1699, 1: 754}\n",
            "\n",
            "Example sensor prediction: {'prob_fertile': 0.0004510940095782499, 'label': 'non_fertile', 'issues': ['Low_moisture (10.7%)', 'N_def', 'P_def', 'K_def']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvWKHooHF7XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TESTING**"
      ],
      "metadata": {
        "id": "5AgNDNYsOhkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from joblib import load\n",
        "import pandas as pd\n",
        "\n",
        "# ----- CONFIG -----\n",
        "MODEL_DIR = \"/content/drive/MyDrive/FarmEasy/soil/soil_model_combined_output_nooverfit\"\n",
        "\n",
        "FEATURE_COLS = [\n",
        "    'Moisture_%','Temperature_C','EC_uS_cm','pH',\n",
        "    'N_mg_per_kg','P_mg_per_kg','K_mg_per_kg'\n",
        "]\n",
        "\n",
        "# ---------- Load saved models ----------\n",
        "print(\"Loading models...\")\n",
        "\n",
        "scaler = load(f\"{MODEL_DIR}/scaler.joblib\")\n",
        "rf_model = load(f\"{MODEL_DIR}/rf_model.joblib\")\n",
        "\n",
        "xgb_booster = xgb.Booster()\n",
        "xgb_booster.load_model(f\"{MODEL_DIR}/xgb_model.json\")\n",
        "\n",
        "calibrator = load(f\"{MODEL_DIR}/calibrator.joblib\")\n",
        "\n",
        "print(\"Models loaded successfully.\\n\")\n",
        "\n",
        "# ---------- Nutrient rule-based assistance ----------\n",
        "def nutrient_suggestions(row):\n",
        "    issues = []\n",
        "    if row['pH'] < 5.5 or row['pH'] > 7.5:\n",
        "        issues.append(\"‚ö† pH out of ideal range (5.5‚Äì7.5)\")\n",
        "    if row['EC_uS_cm'] >= 1000:\n",
        "        issues.append(\"‚ö† High EC (salinity too high)\")\n",
        "    if row['Temperature_C'] < 20 or row['Temperature_C'] > 30:\n",
        "        issues.append(\"‚ö† Temperature not ideal (20‚Äì30¬∞C)\")\n",
        "    if row['Moisture_%'] < 30:\n",
        "        issues.append(\"‚ö† Soil moisture too low (<30%)\")\n",
        "    if row['N_mg_per_kg'] < 20:\n",
        "        issues.append(\"‚ö† Nitrogen deficiency\")\n",
        "    if row['P_mg_per_kg'] < 12:\n",
        "        issues.append(\"‚ö† Phosphorus deficiency\")\n",
        "    if row['K_mg_per_kg'] < 100:\n",
        "        issues.append(\"‚ö† Potassium deficiency\")\n",
        "    return issues\n",
        "\n",
        "# ---------- Function to predict from user input ----------\n",
        "def predict_one():\n",
        "    print(\"\\nEnter soil readings:\\n\")\n",
        "\n",
        "    user_input = {}\n",
        "    for feat in FEATURE_COLS:\n",
        "        user_input[feat] = float(input(f\"Enter {feat}: \"))\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame([user_input])\n",
        "\n",
        "    # Scale (model expects scaled)\n",
        "    X_scaled = scaler.transform(df.values)\n",
        "\n",
        "    # RandomForest probability\n",
        "    p_rf = rf_model.predict_proba(X_scaled)[:,1]\n",
        "\n",
        "    # XGBoost probability\n",
        "    dmat = xgb.DMatrix(X_scaled)\n",
        "    p_xgb = xgb_booster.predict(dmat)\n",
        "\n",
        "    # Stacked probability (RF + XGB ‚Üí Calibrator)\n",
        "    p_final = calibrator.predict_proba(np.column_stack([p_rf, p_xgb]))[:,1][0]\n",
        "\n",
        "    label = \"fertile\" if p_final >= 0.5 else \"non_fertile\"\n",
        "\n",
        "    issues = nutrient_suggestions(user_input)\n",
        "\n",
        "    print(\"\\n---------------------------\")\n",
        "    print(\" **SOIL FERTILITY RESULT**\")\n",
        "    print(\"---------------------------\")\n",
        "    print(f\" Probability fertile: {p_final:.4f}\")\n",
        "    print(f\" Final label: {label.upper()}\")\n",
        "\n",
        "    if issues:\n",
        "        print(\"\\n‚ö† Nutrient / Condition Issues:\")\n",
        "        for i in issues:\n",
        "            print(\" -\", i)\n",
        "    else:\n",
        "        print(\"\\n No major issues detected.\")\n",
        "\n",
        "    print(\"---------------------------\\n\")\n",
        "\n",
        "predict_one()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LarwnoUR1th",
        "outputId": "cfd6a721-754d-436f-ec60-fbde8ca2c49a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models...\n",
            "Models loaded successfully.\n",
            "\n",
            "\n",
            "Enter soil readings:\n",
            "\n",
            "Enter Moisture_%: 67\n",
            "Enter Temperature_C: 16\n",
            "Enter EC_uS_cm: 69\n",
            "Enter pH: 5\n",
            "Enter N_mg_per_kg: 45\n",
            "Enter P_mg_per_kg: 32\n",
            "Enter K_mg_per_kg: 12\n",
            "\n",
            "---------------------------\n",
            "üåæ **SOIL FERTILITY RESULT**\n",
            "---------------------------\n",
            "üìå Probability fertile: 0.0010\n",
            "üìå Final label: NON_FERTILE\n",
            "\n",
            "‚ö† Nutrient / Condition Issues:\n",
            " - ‚ö† pH out of ideal range (5.5‚Äì7.5)\n",
            " - ‚ö† Temperature not ideal (20‚Äì30¬∞C)\n",
            " - ‚ö† Potassium deficiency\n",
            "---------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdoVWmgrR2jh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}